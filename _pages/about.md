---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<!-- ## About Me -->
I am a final-year PhD student (2017 - present) of [Language Technology Institute](https://www.lti.cs.cmu.edu) in the School of Computer Science at [Carnegie Mellon University](https://www.cmu.edu). I am fortunate to be co-advised by Prof. [Graham Neubig](http://www.phontron.com) and Prof. [Taylor Berg-Kirkpatrick](https://cseweb.ucsd.edu/~tberg/). Before that, I received bachelor degree in Electronic Engineering from Shanghai Jiao Tong University. I received the Baidu PhD Fellowship in 2020. 

I have interned at Facebook AI Research (2019), working with [Jiatao Gu](https://jiataogu.me) and [Marc'Aurelio Ranzato](https://ranzato.github.io); interned at Salesforce Research (2020), working with [Bryan McCann](https://bmccann.github.io); and visited Machine Learning Deparment of Carnegie Mellon University (2016), working with [Zhiting Hu](http://zhiting.ucsd.edu) and [Eric Xing](https://www.cs.cmu.edu/~epxing/). 
        
I am generally interested in natural language processing and machine learning. My research covers (latent-variable) generative models, controllable text generation, efficient text generation, and non-parametric language models. Recently I am spending more time on non-parametric methods and their broader roles in NLP.


## Publications
**Towards a Unified View of Parameter-Efficient Transfer Learning**  
*Junxian He*\*, Chunting Zhou* (equal contribution), Xuezhe Ma, Taylor Berg-Kirkpatrick, Graham Neubig   
ICLR 2022 (<span style="color:red">spotlight</span>). [[OpenReview]](https://openreview.net/forum?id=0RDcd5Axok) [[arxiv]](http://arxiv.org/abs/2110.04366) [[code]](https://github.com/jxhe/unify-parameter-efficient-tuning)

**Capturing Structural Locality in Non-parametric Language Models**  
Frank F. Xu, *Junxian He*, Graham Neubig, Vincent Josua Hellendoorn  
ICLR 2022. [[arxiv]](https://arxiv.org/abs/2110.02870)

**Efficient Nearest Neighbor Language Models**  
*Junxian He*, Graham Neubig, Taylor Berg-Kirkpatrick  
EMNLP 2021. [[arxiv]](https://arxiv.org/abs/2109.04212) [[code]](https://github.com/jxhe/efficient-knnlm)

**The Source-Target Domain Mismatch Problem in Machine Translation**  
Jiajun Shen, Peng-Jen Chen, Matthew Le, *Junxian He*, Jiatao Gu, Myle Ott, Michael Auli, Marc'Aurelio Ranzato  
EACL 2021. [[arxiv]](https://arxiv.org/abs/1909.13151)

**Dependency Induction Through the Lens of Visual Perception**  
Ruisi Su, Shruti Rijhwani, Hao Zhu, *Junxian He*, Xinyu Wang, Yonatan Bisk, Graham Neubig  
CoNLL 2021. [[arxiv]](https://arxiv.org/abs/2109.09790) [[code]](https://github.com/ruisi-su/concrete_dep)

**CTRLsum: Towards Generic Controllable Text Summarization**  
*Junxian He*, Wojciech Kryściński, Bryan McCann, Nazneen Rajani, Caiming Xiong  
Preprint 2020. [[arxiv]](https://arxiv.org/abs/2012.04281) [[code]](https://github.com/salesforce/ctrl-sum) [[huggingface demo]](https://huggingface.co/spaces/akhaliq/ctrl-sum) [[streamlit demo]](https://share.streamlit.io/jxhe/ctrlsum-demo/ctrlsum_demo.py)

**Learning Sparse Protoypes for Text Generation**  
*Junxian He*, Taylor Berg-Kirkpatrick, Graham Neubig  
NeurIPS 2020. [[arxiv]](https://arxiv.org/abs/2006.16336) [[code]](https://github.com/jxhe/sparse-text-prototype)

**Revisiting Self-Training for Neural Sequence Generation**  
*Junxian He*\*, Jiatao Gu* (equal contribution), Jiajun Shen, Marc'Aurelio Ranzato  
ICLR 2020. [[arxiv]](https://arxiv.org/abs/1909.13788) [[code]](https://github.com/jxhe/self-training-text-generation)

**A Probabilistic Formulation of Unsupervised Text Style Transfer**  
*Junxian He*\*, Xinyi Wang* (equal contribution), Graham Neubig, Taylor Berg-Kirkpatrick  
ICLR 2020 (<span style="color:red">spotlight</span>). [[arxiv]](https://arxiv.org/abs/2002.03912) [[code]](https://github.com/cindyxinyiwang/deep-latent-sequence-model)

**On the Sentence Embeddings from Pre-trained Language Models**  
Bohan Li, Hao Zhou, *Junxian He*, Mingxuan Wang, Yiming Yang, Lei Li  
EMNLP 2020. [[arxiv]](https://arxiv.org/abs/2011.05864) [[code]](https://github.com/bohanli/BERT-flow)

**A Surprisingly Effective Fix for Deep Latent Variable Modeling of Text**  
Bohan Li\*, *Junxian He*\* (equal contribution), Graham Neubig, Taylor Berg-Kirkpatrick, Yiming Yang  
EMNLP 2019 (short paper). [[arxiv]](https://arxiv.org/abs/1909.00868) [[code]](https://github.com/bohanli/vae-pretraining-encoder)

**Cross-Lingual Syntactic Transfer through Unsupervised Adaptation of Invertible Projections**  
*Junxian He*, Zhisong Zhang, Taylor Berg-Kirkpatrick, Graham Neubig  
ACL 2019. [[arxiv]](https://arxiv.org/abs/1906.02656) [[code]](https://github.com/jxhe/cross-lingual-struct-flow)

**Texar: A modularized, versatile, and extensible toolkit for text generation**  
Zhiting Hu, Haoran Shi, Bowen Tan, Wentao Wang, Zichao Yang, Tiancheng Zhao, *Junxian He*, Lianhui Qin, Di Wang, Xuezhe Ma, Zhengzhong Liu, Xiaodan Liang, Wangrong Zhu, Devendra Singh Sachan, Eric P. Xing  
ACL 2019 (demo paper). <span style="color:red">Best demo paper nomination</span>. [[arxiv]](https://arxiv.org/abs/1809.00794) [[GitHub]](https://github.com/asyml/texar)

**Lagging Inference Networks and Posterior Collapse in Variational Autoencoders**  
*Junxian He*, Daniel Spokoyny, Graham Neubig, Taylor Berg-Kirkpatrick  
ICLR 2019. [[arxiv]](http://arxiv.org/abs/1901.05534) [[code]](https://github.com/jxhe/vae-lagging-encoder)

**Unsupervised Learning of Syntactic Structure with Invertible Neural Projections**   
*Junxian He*, Graham Neubig, Taylor Berg-Kirkpatrick  
EMNLP 2018. [[arxiv]](https://arxiv.org/abs/1808.09111) [[code]](https://github.com/jxhe/struct-learning-with-flow)

**StructVAE: Tree-structured Latent Variable Models for Semi-supervised Semantic Parsing**  
Pengcheng Yin, Chunting Zhou, *Junxian He*, Graham Neubig  
ACL 2018. [[arxiv]](https://arxiv.org/abs/1806.07832)

**Efficient Correlated Topic Modeling with Topic Embedding**  
*Junxian He*\*, Zhiting Hu* (equal contribution), Taylor Berg-Kirkpatrick, Ying Huang, Eric Xing  
KDD 2017. [[arxiv]](https://arxiv.org/abs/1707.00206)

**Text Network Exploration via Heterogeneous Web of Topics**  
*Junxian He*, Ying Huang, Changfeng Liu, Jiaming Shen, Yuting Jia, Xinbing Wang  
ICDM 2016 WorkShop. [[arxiv]](https://arxiv.org/abs/1610.00219) [[demo]]({{ site.baseurl }}/demo/TopicAtlas/CiteseerX.html) 

## Awards
Baidu PhD Fellowship, class of 2020 (10 recipients worldwide)  
Outstanding Undergraduate Thesis (top 1%)  
National Scholarship (2014/2015/2016)
